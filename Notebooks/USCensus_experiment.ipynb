{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb35a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from rankingFairness.src.utils import set_seed, PlattCalibrator\n",
    "from rankingFairness.src.experimentMultipleGroups import simpleOfflineMultipleGroups\n",
    "from rankingFairness.src.utils import set_seed\n",
    "from rankingFairness.src.distributions import Bernoulli, Multinomial, Drichlet, BetaBernoulli\n",
    "from sklearn.calibration import calibration_curve\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8487fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a90dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "state=\"AL\"\n",
    "income_threshold=50000\n",
    "group_name='RAC1P'\n",
    "sim=10\n",
    "num_groups=2\n",
    "markers=['s', 'X', 'o', 'P']\n",
    "labels_use=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc21743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folktables\n",
    "from folktables import ACSDataSource, ACSEmployment, ACSEmploymentFiltered, ACSIncomePovertyRatio, ACSMobility\n",
    "from folktables import ACSIncome, generate_categories\n",
    "\n",
    "SEED=0\n",
    "np.random.seed(SEED)\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[str(state)], download=True)\n",
    "definition_df = data_source.get_definitions(download=True)\n",
    "ACSIncome = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'OCCP',\n",
    "        'POBP',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > income_threshold,    \n",
    "    group=group_name,\n",
    "    preprocess=folktables.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "categories = generate_categories(features=ACSIncome.features, definition_df=definition_df)\n",
    "features, labels, group_df = ACSIncome.df_to_pandas(acs_data, categories=categories, dummies=True)\n",
    "label=labels.values.squeeze()\n",
    "group = group_df.values.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e60d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dict=categories[str(group_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dddcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b820ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainTestIdx(df, train_size=0.5):\n",
    "    idxs = np.array(df.index)\n",
    "    train_idxs = np.random.choice(idxs, size=int(len(idxs)*train_size), replace=False)\n",
    "    test_idxs = np.setdiff1d(idxs, train_idxs)\n",
    "    assert len(np.intersect1d(train_idxs, test_idxs))==0\n",
    "    return train_idxs, test_idxs\n",
    "train_idxs, test_idxs = getTrainTestIdx(features, 0.6)\n",
    "test_idxs, val_idxs = getTrainTestIdx(features.iloc[test_idxs], 0.5)\n",
    "assert len(np.intersect1d(train_idxs, test_idxs))==0\n",
    "assert len(np.intersect1d(train_idxs, val_idxs))==0\n",
    "assert len(np.intersect1d(val_idxs, test_idxs))==0\n",
    "tr=len(train_idxs)\n",
    "v=len(val_idxs)\n",
    "t=len(test_idxs)\n",
    "print(f\"train %:{tr*100/(tr+v+t):.2f}, val %:{v*100/(tr+v+t):.2f}, test %:{t*100/(tr+v+t):.2f}\")\n",
    "print(f\"total dataset:{tr+v+t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de9d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df,  train_idxs, columns_to_norm):\n",
    "    \"\"\"\"Normalizes the data as Goel et al do - continuous features only\"\"\"\n",
    "    \n",
    "    df_unnormed_train = df.iloc[train_idxs].copy()\n",
    "    for feature_name in columns_to_norm:\n",
    "        df[feature_name] = df[feature_name] - np.mean(df_unnormed_train[feature_name])\n",
    "        df[feature_name]  = df[feature_name] / np.std(df_unnormed_train[feature_name])\n",
    "    return df\n",
    "\n",
    "columns_to_norm = ['AGEP', 'WKHP']\n",
    "features = normalize_data(features.copy(),  train_idxs, columns_to_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e778c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=features.iloc[train_idxs].to_numpy()\n",
    "X_val=features.iloc[val_idxs].to_numpy()\n",
    "X_test=features.iloc[test_idxs].to_numpy()\n",
    "\n",
    "y_train=label[train_idxs]\n",
    "y_val=label[val_idxs]\n",
    "y_test=label[test_idxs]\n",
    "\n",
    "group_train=group[train_idxs]\n",
    "group_val=group[val_idxs]\n",
    "group_test=group[test_idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c599e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypertune(model, params_dict, train_X, train_y, cv=5):\n",
    "    \"\"\"\n",
    "    Given a dict of params distributions, do a randomized search\n",
    "    with k-fold cross validation\n",
    "    Args:\n",
    "        model: base classifier\n",
    "        params_dict: dict with distribution of each param\n",
    "        train_X, train_y: train+val data \n",
    "    Returns:\n",
    "        best params dict after randomized search cv with k-folds\n",
    "    \"\"\"\n",
    "    model=RandomizedSearchCV(model, params_dict, random_state=0, scoring='neg_log_loss', cv=cv)\n",
    "    search = model.fit(train_X, train_y)\n",
    "    print(f\"cv results:{search.cv_results_}\")\n",
    "    print(f\"best score: {search.best_score_}\")\n",
    "    print(f\" best params:{search.best_params_}\")\n",
    "    return search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2413337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = GradientBoostingClassifier(max_depth=5, loss='exponential', n_estimators=100, random_state=SEED)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117de83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "np.testing.assert_array_equal (np.unique(yhat), np.array([0, 1])), f\"{np.unique(yhat)}\"\n",
    "yhat = yhat.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "np.testing.assert_array_equal (np.unique(y_test), np.array([0, 1])), f\"{np.unique(y_test)}\"\n",
    "white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "print(f\"total_accuracy:{len(yhat[yhat==y_test])/len(yhat)}\")\n",
    "yhat_white=yhat[group_test==1].astype(int)\n",
    "yhat_black=yhat[group_test==2].astype(int)\n",
    "y_test_white=y_test[group_test==1]\n",
    "y_test_black=y_test[group_test==2]\n",
    "print(f\"{group_dict[1]} accuracy:{len(yhat_white[yhat_white==y_test_white])/len(yhat_white)}\")\n",
    "print(f\"{group_dict[2]} accuracy:{len(yhat_black[yhat_black==y_test_black])/len(yhat_black)}\")\n",
    "print(f\"EO violation:{group_dict[1]} tpr - {group_dict[2]} tpr:{white_tpr - black_tpr}\")\n",
    "print(f\"DP violation:{np.mean(yhat_white)-np.mean(yhat_black)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5762914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_groups>2:\n",
    "    yhat_asian=yhat[group_test==6].astype(int)\n",
    "    y_test_asian=y_test[group_test==6]\n",
    "    print(f\"{group_dict[6]} accuracy:{len(yhat_asian[yhat_asian==y_test_asian])/len(yhat_asian)}\")\n",
    "    if num_groups==4:\n",
    "        yhat_other=yhat[group_test==8].astype(int)\n",
    "        y_test_other=y_test[group_test==8]\n",
    "        print(f\"{group_dict[8]} accuracy:{len(yhat_other[yhat_other==y_test_other])/len(yhat_other)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9fb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_val = model.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04588e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_clf = CalibratedClassifierCV(model, cv='prefit')\n",
    "calibrated_clf.fit(X_val[group_val == 1], y_val[group_val == 1])\n",
    "calibrated_clf.fit(X_val[group_val == 2], y_val[group_val == 2])\n",
    "if num_groups>2:\n",
    "    y_prob_asian=y_prob_val[group_val == 6]\n",
    "    calibrated_clf.fit(X_val[group_val == 6], y_val[group_val == 6])\n",
    "    if num_groups==4:\n",
    "        y_prob_other=y_prob_val[group_val == 8]\n",
    "        calibrated_clf.fit(X_val[group_val == 8], y_val[group_val == 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6146d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After calibration\n",
    "fig, ax =plt.subplots(figsize=(5,5))\n",
    "offset=0.05\n",
    "n_bins=20\n",
    "\n",
    "y_prob_white=calibrated_clf.predict_proba(X_val[group_val == 1])[:,1]\n",
    "prob_true_white, prob_pred_white = calibration_curve(y_val[group_val == 1], y_prob_white , n_bins=n_bins, strategy='quantile')\n",
    "ax.scatter(prob_pred_white, prob_true_white, s=80, c='teal', label=group_dict[1])\n",
    "\n",
    "y_prob_black=calibrated_clf.predict_proba(X_val[group_val == 2])[:,1]\n",
    "prob_true_black, prob_pred_black = calibration_curve(y_val[group_val == 2], y_prob_black , n_bins=n_bins, strategy='quantile')\n",
    "ax.scatter(prob_pred_black, prob_true_black, s=80, c='lightpink', label=group_dict[2])\n",
    "\n",
    "\n",
    "axis_min=min(prob_true_white.min(), prob_pred_white.min(), prob_true_black.min(), prob_pred_black.min())\n",
    "axis_max=max(prob_true_white.max(), prob_pred_white.max(), prob_true_black.max(), prob_pred_black.max())\n",
    "ax.plot([axis_min, axis_max],[axis_min, axis_max],\n",
    "        linestyle='--', color='black', linewidth=2, label=\"Perfect calibration\")\n",
    "ax.set_xlabel('Mean predicted rate', fontsize=20)\n",
    "ax.set_ylabel('Mean empirical rate', fontsize=20)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.legend( loc='upper left',markerscale=1., scatterpoints=1, fontsize=12)\n",
    "ax.set_xlim(axis_min-offset, axis_max+offset)\n",
    "ax.set_ylim(axis_min-offset, axis_max+offset)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names=['White', 'Black', 'Asian', 'Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac50b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(figsize=(5,5))\n",
    "offset=0.05\n",
    "n_bins=20\n",
    "\n",
    "y_test_prob_white=calibrated_clf.predict_proba(X_test[group_test == 1])[:,1]\n",
    "prob_true_white, prob_pred_white = calibration_curve(y_test[group_test == 1], y_test_prob_white , n_bins=n_bins, strategy='quantile')\n",
    "ax.scatter(prob_pred_white, prob_true_white, s=80, marker=markers[0], facecolors='w',label=group_names[0])\n",
    "\n",
    "y_test_prob_black=calibrated_clf.predict_proba(X_test[group_test == 2])[:,1]\n",
    "prob_true_black, prob_pred_black = calibration_curve(y_test[group_test == 2], y_test_prob_black , n_bins=n_bins, strategy='quantile')\n",
    "ax.scatter(prob_pred_black, prob_true_black, s=80, marker=markers[1], facecolors='w', label=group_names[1])\n",
    "\n",
    "\n",
    "axis_min=min(prob_true_white.min(), prob_pred_white.min(), prob_true_black.min(), prob_pred_black.min())\n",
    "axis_max=max(prob_true_white.max(), prob_pred_white.max(), prob_true_black.max(), prob_pred_black.max())\n",
    "ax.plot([axis_min, axis_max],[axis_min, axis_max],\n",
    "        linestyle='--', color='black', linewidth=2, label=\"Perfect calibration\")\n",
    "ax.set_xlabel('Mean predicted rate', fontsize=20)\n",
    "ax.set_ylabel('Mean empirical rate', fontsize=20)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "legend = ax.legend( loc='upper left',markerscale=1., scatterpoints=1, fontsize=12)\n",
    "ax.set_xlim(axis_min-offset, axis_max+offset)\n",
    "ax.set_ylim(axis_min-offset, axis_max+offset)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if num_groups>2:\n",
    "    fig, ax =plt.subplots(figsize=(5,5))\n",
    "    offset=0.05\n",
    "    n_bins=20\n",
    "\n",
    "    y_test_prob_white=calibrated_clf.predict_proba(X_test[group_test == 1])[:,1]\n",
    "    prob_true_white, prob_pred_white = calibration_curve(y_test[group_test == 1], y_test_prob_white , n_bins=n_bins, strategy='quantile')\n",
    "    ax.scatter(prob_pred_white, prob_true_white, s=80, marker=markers[0], facecolors='w',label=group_names[0])\n",
    "\n",
    "    y_test_prob_black=calibrated_clf.predict_proba(X_test[group_test == 2])[:,1]\n",
    "    prob_true_black, prob_pred_black = calibration_curve(y_test[group_test == 2], y_test_prob_black , n_bins=n_bins, strategy='quantile')\n",
    "    ax.scatter(prob_pred_black, prob_true_black, s=80, marker=markers[1], facecolors='w',label=group_names[1])\n",
    "\n",
    "    y_test_prob_asian=calibrated_clf.predict_proba(X_test[group_test == 6])[:,1]\n",
    "    prob_true_asian, prob_pred_asian = calibration_curve(y_test[group_test == 6], y_test_prob_asian , n_bins=n_bins, strategy='quantile')\n",
    "    ax.scatter(prob_pred_asian, prob_true_asian, s=80, marker=markers[2], facecolors='w',label=group_names[2])\n",
    "    \n",
    "    axis_min=min(prob_true_asian.min(), prob_pred_asian.min(),\n",
    "                 prob_true_white.min(), prob_pred_white.min(),\n",
    "                 prob_true_black.min(), prob_pred_black.min())\n",
    "    axis_max=max(prob_true_asian.max(), prob_pred_asian.max(),\n",
    "                 prob_true_white.max(), prob_pred_white.max(),\n",
    "                 prob_true_black.max(), prob_pred_black.max())\n",
    "    if num_groups==4:\n",
    "        y_test_prob_other=calibrated_clf.predict_proba(X_test[group_test == 8])[:,1]\n",
    "        prob_true_other, prob_pred_other = calibration_curve(y_test[group_test == 8], y_test_prob_other , n_bins=n_bins, strategy='quantile')\n",
    "        ax.scatter(prob_pred_other, prob_true_other, s=80, marker=markers[3], facecolors='w',label=group_names[3])\n",
    "        axis_min=min(prob_true_asian.min(), prob_pred_asian.min(),\n",
    "                 prob_true_white.min(), prob_pred_white.min(),\n",
    "                 prob_true_black.min(), prob_pred_black.min(),\n",
    "                 prob_true_other.min(), prob_pred_other.min())\n",
    "        axis_max=max(prob_true_asian.max(), prob_pred_asian.max(),\n",
    "                 prob_true_white.max(), prob_pred_white.max(),\n",
    "                 prob_true_black.max(), prob_pred_black.max(),\n",
    "                 prob_true_other.max(), prob_pred_other.max())\n",
    "    ax.plot([axis_min, axis_max],[axis_min, axis_max],\n",
    "            linestyle='--', color='black', linewidth=2, label=\"Perfect calibration\")\n",
    "    ax.set_xlabel('Mean predicted rate', fontsize=20)\n",
    "    ax.set_ylabel('Mean empirical rate', fontsize=20)\n",
    "    ax.tick_params(axis='y', labelsize=15)\n",
    "    ax.tick_params(axis='x', labelsize=15)\n",
    "    legend = ax.legend( loc='upper left',markerscale=1., scatterpoints=1, fontsize=12)\n",
    "    ax.set_xlim(axis_min-offset, axis_max+offset)\n",
    "    ax.set_ylim(axis_min-offset, axis_max+offset)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c5a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
    "plt.hist(y_test_prob_white, label=group_dict[1], bins=50, alpha=0.5)\n",
    "plt.hist(y_test_prob_black, label=group_dict[2], bins=50, alpha=0.5)\n",
    "if num_groups>2:\n",
    "    plt.hist(y_test_prob_asian, label=group_dict[6], bins=50, alpha=0.5)\n",
    "    if num_groups==4:\n",
    "        plt.hist(y_test_prob_other, label=group_dict[8], bins=50, alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel(r'Calibrated $\\mathbb{P}(r_i|\\mathbb{D})$', fontsize=15)\n",
    "plt.ylabel(r'Counts', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3439fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    print(\"Train \\n\")\n",
    "    print(f\" race:{group_dict[i]}, len:{len(X_train[group_train == i])}\")\n",
    "    print(\"Val \\n\")\n",
    "    print(f\" race:{group_dict[i]}, len:{len(X_val[group_val == i])}\")\n",
    "    print(\"test \\n\")\n",
    "    print(f\" race:{group_dict[i]}, len:{len(X_test[group_test == i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c450a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" sum white probs:{y_test_prob_white.sum()},sum black probs:{y_test_prob_black.sum()}\")\n",
    "if num_groups>2:\n",
    "    print(f\" sum asian probs: {y_test_prob_asian.sum()}\")\n",
    "    if num_groups==4:\n",
    "        print(f\" sum other race probs:{y_test_prob_other.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ccf3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_groups==2:\n",
    "    from rankingFairness.src.rankingsMultipleGroups import PRP_Ranker, EO_RankerII, TS_RankerII, DP_Ranker, Uniform_Ranker\n",
    "    rankingAlgos=[PRP_Ranker, EO_RankerII, TS_RankerII, DP_Ranker, Uniform_Ranker]\n",
    "    A_true = y_test_prob_white\n",
    "    B_true = y_test_prob_black\n",
    "\n",
    "    A_dist = [Bernoulli(p) for p in A_true]\n",
    "    B_dist = [Bernoulli(p) for p in B_true]\n",
    "\n",
    "    merits_white = y_test[group_test==1].astype(float)\n",
    "    merits_black = y_test[group_test==2].astype(float)\n",
    "    merits = np.hstack((merits_white, merits_black))[None,:]\n",
    "\n",
    "    assert merits.shape[0]==1\n",
    "    assert merits.shape[1]==len(A_dist)+len(B_dist)\n",
    "    num_docs=len(A_true)+len(B_true)\n",
    "\n",
    "    if labels_use:\n",
    "        exp = simpleOfflineMultipleGroups(num_groups=num_groups, num_docs=num_docs, \n",
    "            predfined_ls=[A_dist, B_dist], distType=BetaBernoulli, merits=merits, verbose=True)\n",
    "    else:\n",
    "        exp = simpleOfflineMultipleGroups(num_groups=num_groups, num_docs=num_docs, \n",
    "            predfined_ls=[A_dist, B_dist], distType=BetaBernoulli, verbose=True)\n",
    "    exp.experiment(rankingAlgos=rankingAlgos, simulations=sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ranking_uncertainty",
   "language": "python",
   "name": "ranking_uncertainty"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
